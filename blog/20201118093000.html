<!DOCTYPE html>
<html>
  <head>
    <!-- meta -->

<!-- Google Automatic Advertising -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4525414114581084"
     crossorigin="anonymous"></script>

<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0">
<link rel="icon" type="image/x-icon" href="/images/logo.png">
<link rel="stylesheet" type="text/css" href="/css/common.css">

<script type="text/javascript" src="/js/jquery-1.9.0.min.js"></script>
<script type="text/javascript" src="/js/google-code-prettify/prettify.js"></script>
<link  type="text/css" rel="stylesheet" href="/js/google-code-prettify/prettify.css"/>
<script>
  $(function(){
    // google code prettifyの有効化
    $("pre").addClass("prettyprint");
    function init(event){
      prettyPrint();
    }
    if(window.addEventListener)window.addEventListener("load",init,false);
    else if(window.attachEvent)window.attachEvent("onload",init);
    
    $(".to-top").click(function() {
      // ページの一番上までスクロールさせます。
      $('body, html').animate({scrollTop: 0}, 300, 'linear');;
    });
  });
</script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-5YWD0EFVYR"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-5YWD0EFVYR');
</script>

<title>Perlのディープラーニングのライブラリ - AI::MXNet - Perl深層学習AI入門</title>
<meta name="description" content="Perlのディープラーニングライブラリには、AI::MXNetがあります。C++で書かれたディープラーニングのライブラリをPerlでバインディングして利用できるようにしたものです。">
  </head>
  <body>
    <div class="container">
      <div class="header">
        <div class="header_main">
  <h1>
    <a href="/"><img src="/images/logo.png">Perl AI深層学習入門</a>
  </h1>
  <div class="header_right">
    <a rel="nofollow" href="https://perlclub.net"><img src="/images/perl_club_logo.png"></a>
  </div>
</div>

      </div>
      <div class="main">
        <div class="content">
          <div class="entry">
  <div class="top">
    <!-- top -->

  </div>
  <div class="middle">
    <h2><a href="/blog/20201118093000.html">Perlのディープラーニングのライブラリ - AI::MXNet</a></h2>
<p>
  Perlのディープラーニングライブラリには、<a href="https://metacpan.org/pod/AI::MXNet">AI::MXNet</a>があります。C++で書かれたディープラーニングのライブラリをPerlでバインディングして利用できるようにしたものです。
</p>
<div style="width:calc(100% - 30px);margin:10px auto;">
  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4525414114581084"
       crossorigin="anonymous"></script>
  <!-- 最初の段落下 - ディスプレイ 横長 レスポンシブ -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-4525414114581084"
       data-ad-slot="2828858335"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


<p>
  まずは、実際にディープラーニングを試してみたいという方は、ライブラリを使うと簡単に(?)できます。ディープラーニングは深層学習とも呼ばれます。深層学習のPerlのライブラリを探している方も、AI::MXNetがそれです。
</p>
<h3>MXNetのAmazon AWSにおける公式サポート</h3>
<p>
  MXNetはAmazon AWSにおける公式サポートがあります。
</p>
<blockquote>
<p>
  柔軟性と選択肢
</p>
<p>
  <b>MXNet</b>では、C++、JavaScript、Python、R、Matlab、Julia、Scala、Clojure、<b>Perl</b> といったプログラミング言語が幅広くサポートされているため、自分のすでに知っている言語で開始することができます。ただし、バックエンドではすべてのコードが C++ にコンパイルされるため、モデル構築に使用された言語にかかわりなく最大限のパフォーマンスを発揮できます。
</p>
<p>
  <a href="https://aws.amazon.com/jp/mxnet/">AWS での Apache MXNet</a>
</p>
</blockquote>
<p>
  AI::MXNetは、数少ないAmazon Perlサポートのひとつです...。
</p>
<h3>ディープラーニングを使った画像生成のサンプル</h3>
<p>
  AI::MXNetの作者のSergey V. Kolychevさんの英語のブログによると、ディープラーニングを使ったイメージ生成などもできるようです。作者の方自身は、自然言語処理に関連するディープラーニングを業務で行っているようです。
</p>
<blockquote>
<p>
  この例を楽しんで、素敵な写真をたくさん作り出してほしいですね。以下は、キュウビの写真と異なる古典的な絵画から作られたサンプルスクリプトによって生成された画像です。
</p>
<p>
  <a href="http://blogs.perl.org/users/sergey_kolychev/2018/07/machine-learning-in-perl-kyuubi-goes-to-a-modelzoo-during-the-starry-night.html">Machine learning in Perl: Kyuubi goes to a (Model)Zoo during The Starry Night.</a>
</p>
</blockquote>
<h4>元の画像</h4>
<p>
  <img src="/images/aimxnet/kyuubi.jpg" width="500">
</p>
<h4>ディープラーニングで生成された画像</h4>
<p>
  ゴッホ風画風みたいなのを学習させて、オリジナル画像から生成したものでしょうか。
</p>
<p>
  <img src="/images/aimxnet/kyuubi_blacksquare.jpg">
</p>
<p>
  <img src="/images/aimxnet/kyuubi_dali.jpg">
</p>
<p>
  <img src="/images/aimxnet/kyuubi_mural.jpg">
</p>
<p>
  <img src="/images/aimxnet/kyuubi_starry.jpg">
</p>
<h3>AI::MXNetの使い方</h3>
<p>
  使い方をサンプルから紹介です。
</p>
<pre>
## Convolutional NN for recognizing hand-written digits in MNIST dataset
## It's considered "Hello, World" for Neural Networks
## For more info about the MNIST problem please refer to L&lt;http://neuralnetworksanddeeplearning.com/chap1.html&gt;
 
use strict;
use warnings;
use AI::MXNet qw(mx);
use AI::MXNet::TestUtils qw(GetMNIST_ubyte);
use Test::More tests =&gt; 1;
 
# symbol net
my $batch_size = 100;
 
### model
my $data = mx-&gt;symbol-&gt;Variable('data');
my $conv1= mx-&gt;symbol-&gt;Convolution(data =&gt; $data, name =&gt; 'conv1', num_filter =&gt; 32, kernel =&gt; [3,3], stride =&gt; [2,2]);
my $bn1  = mx-&gt;symbol-&gt;BatchNorm(data =&gt; $conv1, name =&gt; "bn1");
my $act1 = mx-&gt;symbol-&gt;Activation(data =&gt; $bn1, name =&gt; 'relu1', act_type =&gt; "relu");
my $mp1  = mx-&gt;symbol-&gt;Pooling(data =&gt; $act1, name =&gt; 'mp1', kernel =&gt; [2,2], stride =&gt;[2,2], pool_type=&gt;'max');
 
my $conv2= mx-&gt;symbol-&gt;Convolution(data =&gt; $mp1, name =&gt; 'conv2', num_filter =&gt; 32, kernel=&gt;[3,3], stride=&gt;[2,2]);
my $bn2  = mx-&gt;symbol-&gt;BatchNorm(data =&gt; $conv2, name=&gt;"bn2");
my $act2 = mx-&gt;symbol-&gt;Activation(data =&gt; $bn2, name=&gt;'relu2', act_type=&gt;"relu");
my $mp2  = mx-&gt;symbol-&gt;Pooling(data =&gt; $act2, name =&gt; 'mp2', kernel=&gt;[2,2], stride=&gt;[2,2], pool_type=&gt;'max');
 
 
my $fl   = mx-&gt;symbol-&gt;Flatten(data =&gt; $mp2, name=&gt;"flatten");
my $fc1  = mx-&gt;symbol-&gt;FullyConnected(data =&gt; $fl,  name=&gt;"fc1", num_hidden=&gt;30);
my $act3 = mx-&gt;symbol-&gt;Activation(data =&gt; $fc1, name=&gt;'relu3', act_type=&gt;"relu");
my $fc2  = mx-&gt;symbol-&gt;FullyConnected(data =&gt; $act3, name=&gt;'fc2', num_hidden=&gt;10);
my $softmax = mx-&gt;symbol-&gt;SoftmaxOutput(data =&gt; $fc2, name =&gt; 'softmax');
 
# check data
GetMNIST_ubyte();
 
my $train_dataiter = mx-&gt;io-&gt;MNISTIter({
    image=&gt;"data/train-images-idx3-ubyte",
    label=&gt;"data/train-labels-idx1-ubyte",
    data_shape=&gt;[1, 28, 28],
    batch_size=&gt;$batch_size, shuffle=&gt;1, flat=&gt;0, silent=&gt;0, seed=&gt;10});
my $val_dataiter = mx-&gt;io-&gt;MNISTIter({
    image=&gt;"data/t10k-images-idx3-ubyte",
    label=&gt;"data/t10k-labels-idx1-ubyte",
    data_shape=&gt;[1, 28, 28],
    batch_size=&gt;$batch_size, shuffle=&gt;1, flat=&gt;0, silent=&gt;0});
 
my $n_epoch = 1;
my $mod = mx-&gt;mod-&gt;new(symbol =&gt; $softmax);
$mod-&gt;fit(
    $train_dataiter,
    eval_data =&gt; $val_dataiter,
    optimizer_params=&gt;{learning_rate=&gt;0.01, momentum=&gt; 0.9},
    num_epoch=&gt;$n_epoch
);
my $res = $mod-&gt;score($val_dataiter, mx-&gt;metric-&gt;create('acc'));
ok($res-&gt;{accuracy} &gt; 0.8);
 
## Gluon MNIST example
 
my $net = nn-&gt;Sequential();
$net-&gt;name_scope(sub {
    $net-&gt;add(nn-&gt;Dense(128, activation=&gt;'relu'));
    $net-&gt;add(nn-&gt;Dense(64, activation=&gt;'relu'));
    $net-&gt;add(nn-&gt;Dense(10));
});
$net-&gt;hybridize;
 
# data
sub transformer
{
    my ($data, $label) = @_;
    $data = $data-&gt;reshape([-1])-&gt;astype('float32')/255;
    return ($data, $label);
}
my $train_data = gluon-&gt;data-&gt;DataLoader(
    gluon-&gt;data-&gt;vision-&gt;MNIST('./data', train=&gt;1, transform =&gt; \&amp;transformer),
    batch_size=&gt;$batch_size, shuffle=&gt;1, last_batch=&gt;'discard'
);
 
## training
sub train
{
    my ($epochs, $ctx) = @_;
    # Collect all parameters from net and its children, then initialize them.
    $net-&gt;initialize(mx-&gt;init-&gt;Xavier(magnitude=&gt;2.24), ctx=&gt;$ctx);
    # Trainer is for updating parameters with gradient.
    my $trainer = gluon-&gt;Trainer($net-&gt;collect_params(), 'sgd', { learning_rate =&gt; $lr, momentum =&gt; $momentum });
    my $metric = mx-&gt;metric-&gt;Accuracy();
    my $loss = gluon-&gt;loss-&gt;SoftmaxCrossEntropyLoss();
 
    for my $epoch (0..$epochs-1)
    {
        # reset data iterator and metric at begining of epoch.
        $metric-&gt;reset();
        enumerate(sub {
            my ($i, $d) = @_;
            my ($data, $label) = @$d;
            $data = $data-&gt;as_in_context($ctx);
            $label = $label-&gt;as_in_context($ctx);
            # Start recording computation graph with record() section.
            # Recorded graphs can then be differentiated with backward.
            my $output;
            autograd-&gt;record(sub {
                $output = $net-&gt;($data);
                my $L = $loss-&gt;($output, $label);
                $L-&gt;backward;
            });
            # take a gradient step with batch_size equal to data.shape[0]
            $trainer-&gt;step($data-&gt;shape-&gt;[0]);
            # update metric at last.
            $metric-&gt;update([$label], [$output]);
 
            if($i % $log_interval == 0 and $i &gt; 0)
            {
                my ($name, $acc) = $metric-&gt;get();
                print "[Epoch $epoch Batch $i] Training: $name=$acc\n";
            }
        }, \@{ $train_data });
 
        my ($name, $acc) = $metric-&gt;get();
        print "[Epoch $epoch] Training: $name=$acc\n";
 
        my ($val_name, $val_acc) = test($ctx);
        print "[Epoch $epoch] Validation: $val_name=$val_acc\n"
    }
    $net-&gt;save_parameters('mnist.params');
}
 
train($epochs, $cuda ? mx-&gt;gpu(0) : mx-&gt;cpu);
</pre>

  </div>
  <div class="bottom">
    <h3>関連情報</h3>

<div style="margin:10px 0">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4525414114581084"
     crossorigin="anonymous"></script>
<ins class="adsbygoogle"
     style="display:block"
     data-ad-format="autorelaxed"
     data-ad-client="ca-pub-4525414114581084"
     data-ad-slot="9163995495"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
</div>

  </div>
</div>

        </div>
        <div class="side">
          
        </div>
      </div>
      <div class="footer">
        <div class="footer-services">
  <ul>
    <li><a href="https://perlzemi.com/">Perlゼミ</a></li>
    <li><a href="https://en.perlzemi.com/">Perl ABC</a></li>
    <li><a rel="nofollow" href="/list.html">新着情報</a></li>
    <li><a rel="nofollow" href="https://perlclub.net/sites">無料Web講座</a></li>
    <li><a rel="nofollow" href="https://perlclub.net/book">書籍・電子書籍</a></li>
    <li><a rel="nofollow" href="https://twitter.com/perlzemi">Twitter</a>
    <li><a rel="nofollow" href="https://www.youtube.com/channel/UCbeAS6ZXpSKqkzb-Nykb0ZQ">Youtube</a>
  </ul>
</div>

<div class="perlri_link">
  <a rel="nofollow" href="https://perlclub.net">Perlクラブ</a>
</div>

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4525414114581084"
     crossorigin="anonymous"></script>
     
      </div>
    </div>
  </body>
</html>
